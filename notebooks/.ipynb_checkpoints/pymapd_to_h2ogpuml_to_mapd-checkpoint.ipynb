{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Open Analytics Initiative: PyMapD to H2OGPUML to MapD\n",
    "\n",
    "### In this demo, we will train 4000 regularized linear regression models on the FIFA Football dataset, with the goal to predict the overall rating of the player, given different  feature sets (such as potential, finishing, strength, etc.)\n",
    "\n",
    "### The dataset has 180k rows, 42 cols, Integer/single-precision floating-point values, so it fits onto the GPU memory.\n",
    "\n",
    "### By using multiple GPUs, we are able to speed up this process significantly, and can train around 40 models per second (on Quadro - 6000 with 4 GPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose to Store predictedictions in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storage=0: Do not store the values in MapD\n",
    "# storage=1: Store the predicted values in MapD\n",
    "\n",
    "storage=1\n",
    "\n",
    "# storage=1: Predicted values will be copied to host memory in the process of inserting records in MapD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PWD = !pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the code below, if pygdf cannot be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raidStorage/wamsi/new/pygdf/notebooks/..\n"
     ]
    }
   ],
   "source": [
    "pygdf_path = os.path.join(PWD[0], '..')\n",
    "print(pygdf_path)\n",
    "#sys.path.append(pygdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PyMapD and PyGDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymapd\n",
    "import pygdf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup MapD Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Established Connection(mapd://mapd:***@10.1.0.4:9998/mapd?protocol=binary)\n"
     ]
    }
   ],
   "source": [
    "db_name = 'mapd'\n",
    "user_name = 'mapd'\n",
    "passwd = 'HyperInteractive'\n",
    "hostname = '10.1.0.4'\n",
    "portno = 9998\n",
    "\n",
    "con = pymapd.connect(user=user_name, password=passwd, host=hostname, dbname=db_name, port=portno)\n",
    "print('Established {}'.format(con))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from MapD to PyGDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No.of columns: 37\n"
     ]
    }
   ],
   "source": [
    "columns = '''overall_rating,rowid AS map_id,potential,CASE WHEN preferred_foot = 'left' THEN 1 WHEN preferred_foot = 'right' THEN 2 ELSE 0 END,crossing,finishing,heading_accuracy,short_passing,volleys,dribbling,curve,free_kick_accuracy,long_passing,ball_control,acceleration,sprint_speed,agility,reactions,balance,shot_power,jumping,stamina,strength,long_shots,aggression,interceptions,positioning,vision,penalties,marking,standing_tackle,sliding_tackle,gk_diving,gk_handling,gk_kicking,gk_positioning,gk_reflexes'''.strip()\n",
    "print('Total No.of columns: %d'%(len(columns.split(','))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select statement is : SELECT overall_rating,rowid AS map_id,potential,CASE WHEN preferred_foot = 'left' THEN 1 WHEN preferred_foot = 'right' THEN 2 ELSE 0 END,crossing,finishing,heading_accuracy,short_passing,volleys,dribbling,curve,free_kick_accuracy,long_passing,ball_control,acceleration,sprint_speed,agility,reactions,balance,shot_power,jumping,stamina,strength,long_shots,aggression,interceptions,positioning,vision,penalties,marking,standing_tackle,sliding_tackle,gk_diving,gk_handling,gk_kicking,gk_positioning,gk_reflexes FROM PLAYER_ATTRIBUTES WHERE overall_rating > 30 ORDER BY ID\n"
     ]
    }
   ],
   "source": [
    "query_select = '''SELECT {} FROM PLAYER_ATTRIBUTES WHERE overall_rating > 30 ORDER BY ID'''.format(columns)\n",
    "print('Select statement is : {}'.format(query_select))\n",
    "\n",
    "df = con.select_ipc_gpu(query_select, device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure extracted data is float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response_col = 'overall_rating'\n",
    "key_col = 'map_id'\n",
    "feature_col = set(df.columns) - set([response_col]) - set([key_col])\n",
    "\n",
    "num_col = set()\n",
    "cat_col = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if storage == 1:\n",
    "    # Create DF with key_col\n",
    "    from pygdf.dataframe import DataFrame\n",
    "    df_src = DataFrame()\n",
    "    df_src.add_column(key_col, df[key_col].astype(np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distinguish Categorical and Numerical columns by computing unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_val = {}\n",
    "for col in feature_col:\n",
    "    try:\n",
    "        val = df[col].unique_k(1000)\n",
    "    except ValueError:\n",
    "        # more than 1000 unique values\n",
    "        num_col.add(col)\n",
    "    else:\n",
    "        # value less than 1000\n",
    "        value = len(val)\n",
    "        if value <= 1:\n",
    "            del df[col]\n",
    "        elif 1 < value < 1000:\n",
    "            cat_col.add(col)\n",
    "        else:\n",
    "            num_col.add(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Columns: Fill null values and Normalize data from 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in num_col:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "    assert df[col].null_count == 0\n",
    "    std = df[col].std()\n",
    "    # drop near constant columns\n",
    "    if not np.isfinite(std) or std < 1e-4:\n",
    "        del df[col]\n",
    "        print('drop near constant', col)\n",
    "    else:\n",
    "        df[col] = df[col].scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical columns: One-hot-encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cat_col:\n",
    "    df[col] = df[col].fillna(-99)\n",
    "    cats = (df[col].unique_k(501))[1:]  # drop first\n",
    "    df = df.one_hot_encoding(col, prefix=col, cats=cats, dtype=np.float32)\n",
    "    del df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add intercept column and unity weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "df['intercept'] = np.ones(nrows, dtype=np.float64)\n",
    "df['weights'] = np.ones(nrows, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure response column is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[response_col] = df[response_col].fillna(df[response_col].mean())\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 60-30 split: training - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60% of 183141 is 128198\n",
      "df_train has 128199 rows | df_test has 128199 rows\n"
     ]
    }
   ],
   "source": [
    "FRACTION=0.7\n",
    "\n",
    "n = int(len(df) * FRACTION)\n",
    "print('60% of {} is {}'.format(len(df), n))\n",
    "df_train = df.loc[:n]\n",
    "\n",
    "df_test = df.loc[n:]\n",
    "if storage == 1:\n",
    "    df_src = df_src.loc[n:]\n",
    "        \n",
    "    print('df_train has {} rows | df_test has {} rows'.format(len(df_train), len(df_train)))\n",
    "else:\n",
    "    print('df_train has {} rows | df_test has {} rows'.format(len(df_train), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make matrices from data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_mat = df_train.as_gpu_matrix(columns=df.columns[1:-1])\n",
    "train_result_mat = df_train.as_gpu_matrix(columns=[df.columns[0]])\n",
    "train_w_mat = df_train.as_gpu_matrix(columns=[df.columns[-1]])\n",
    "test_data_mat = df_test.as_gpu_matrix(columns=df.columns[1:-1])\n",
    "test_result_mat = df_test.as_gpu_matrix(columns=[df.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128199, 3053)\n",
      "(128199, 1)\n",
      "(128199, 1)\n",
      "(54943, 3053)\n",
      "(54943, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_mat.shape)\n",
    "print(train_result_mat.shape)\n",
    "print(train_w_mat.shape)\n",
    "print(test_data_mat.shape)\n",
    "print(test_result_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make ctypes pointers to GPU matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_mat_ptr address 0x105cfe00000\n",
      "train_result_mat_ptr address 0x1062d30a600\n",
      "test_data_mat_ptr address 0x1062d400000\n",
      "test_result_mat_ptr address 0x105c9600000\n"
     ]
    }
   ],
   "source": [
    "train_data_mat_ptr = train_data_mat.device_ctypes_pointer\n",
    "train_result_mat_ptr = train_result_mat.device_ctypes_pointer\n",
    "print('train_data_mat_ptr address', hex(train_data_mat_ptr.value))\n",
    "print('train_result_mat_ptr address', hex(train_result_mat_ptr.value))\n",
    "\n",
    "test_data_mat_ptr = test_data_mat.device_ctypes_pointer\n",
    "test_result_mat_ptr = test_result_mat.device_ctypes_pointer\n",
    "print('test_data_mat_ptr address', hex(test_data_mat_ptr.value))\n",
    "print('test_result_mat_ptr address', hex(test_result_mat_ptr.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2OGPUML: Model training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load H2OGPUML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2ogpuml\n",
    "from ctypes import *\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = train_data_mat.device_ctypes_pointer\n",
    "ytrain = train_result_mat.device_ctypes_pointer\n",
    "xtest = test_data_mat.device_ctypes_pointer\n",
    "ytest = test_result_mat.device_ctypes_pointer\n",
    "wtrain = train_w_mat.device_ctypes_pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params for features, train values, shape\n",
    "n = train_data_mat.shape[1]\n",
    "mTrain = train_data_mat.shape[0]\n",
    "mValid = test_data_mat.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods to display errors and running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_errors(display, enet, givefullpath):\n",
    "    err_best = enet.error_best\n",
    "    alphas_best = enet.alphas_best\n",
    "    lambdas_best = enet.lambdas_best\n",
    "    tols_best = enet.tols_best\n",
    "\n",
    "    if givefullpath == 1:\n",
    "        err_full = enet.error_full\n",
    "        alphas_full = enet.alphas_full\n",
    "        lambdas_full = enet.lambdas_full\n",
    "        tols_full = enet.tols_full\n",
    "\n",
    "    loss = 'RMSE'\n",
    "\n",
    "    if enet.family == 'logistic':\n",
    "        loss = \"LOGLOSS\"\n",
    "\n",
    "    if display == 1:\n",
    "        # Display most important metrics\n",
    "        if givefullpath == 1:\n",
    "            print('Alphas full path: {}'.format(alphas_full))\n",
    "            print('Lambdas full path: {}'.format(lambdas_best))\n",
    "            print('Tols full path: {}'.format(tols_full))\n",
    "            print('RMSE full path: {}'.format(err_full))\n",
    "\n",
    "        print('Alphas: {}'.format(alphas_best))\n",
    "        print('Lambdas: {}'.format(lambdas_best))\n",
    "        print('Tols: {}'.format(tols_best))\n",
    "        print('{}: {}'.format(loss, err_best))\n",
    "\n",
    "    return err_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_glm(nFolds, nAlphas, nLambdas, xtrain, ytrain, xtest, ytest, wtrain):\n",
    "\n",
    "   # params for features, train values, shape\n",
    "    n = train_data_mat.shape[1]\n",
    "    mTrain = train_data_mat.shape[0]\n",
    "    mValid = test_data_mat.shape[0]\n",
    "\n",
    "    maxNGPUS = int(subprocess.check_output(\"nvidia-smi -L | wc -l\", shell=True))\n",
    "    print(\"Maximum Number of GPUS:\", maxNGPUS)\n",
    "    nGPUs = maxNGPUS  # choose all GPUs\n",
    "\n",
    "    print(\"No. of Features=%d mTrain=%d mValid=%d\" % (n, mTrain, mValid))\n",
    "\n",
    "    # Order of data\n",
    "    fortran = 1\n",
    "    print(\"fortran=%d\" % (fortran))\n",
    "\n",
    "    sourceme = 0\n",
    "    sourceDev = 0\n",
    "    nThreads = None  # default value, algo handles it.\n",
    "    precision = 0\n",
    "    # variables\n",
    "    a, b = c_void_p(xtrain.value), c_void_p(ytrain.value)\n",
    "    c, d = c_void_p(xtest.value), c_void_p(ytest.value)\n",
    "    e = c_void_p(wtrain.value)\n",
    "\n",
    "    #print(a, b, c, d, e)\n",
    "\n",
    "    print(\"Setting up Solver\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    Solver = h2ogpuml.GLM\n",
    "    enet = Solver(n_threads=nThreads, n_gpus=nGPUs, order='c' if fortran else 'r', intercept=intercept, \\\n",
    "                  lambda_min_ratio=lambda_min_ratio, n_lambdas=nLambdas, n_folds=nFolds, n_alphas=nAlphas, \\\n",
    "                  verbose=5, give_full_path=givefullpath)\n",
    "\n",
    "    print(\"Solving\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    enet.fit_ptr(sourceDev, mTrain, n, mValid, precision, 'c' if fortran else 'r', a, b, c, d, e, give_full_path=givefullpath)\n",
    "\n",
    "    print(\"Done Solving\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print('Predicting')\n",
    "    sys.stdout.flush()\n",
    "    pred_val = enet.predict_ptr(c, d, give_full_path=givefullpath)\n",
    "\n",
    "    print('Done Predicting')\n",
    "    sys.stdout.flush()\n",
    "    print('predicted values:\\n', pred_val)\n",
    "\n",
    "    loss = get_errors(display, enet, givefullpath)\n",
    "\n",
    "    return pred_val, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Parameters for building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercept = True\n",
    "lambda_min_ratio = 1e-9\n",
    "nAlphas = 8\n",
    "nLambdas = 100\n",
    "nFolds = 5\n",
    "\n",
    "givefullpath = 0\n",
    "display = 1 # To print the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Number of GPUS: 4\n",
      "No. of Features=3053 mTrain=128199 mValid=54943\n",
      "fortran=1\n",
      "Setting up Solver\n",
      "\n",
      "Warning: Cannot create a H2OGPUML Elastic Net CPU Solver instance without linking Python module to a compiled H2OGPUML >CPU library Use GPU or re-run setup.py\n",
      "Using GPU GLM solver with 4 GPUs\n",
      "Solving\n",
      "Done Solving\n",
      "\n",
      "Predicting\n",
      "Done Predicting\n",
      "predicted values:\n",
      " [[ 71.14216614  69.12330627  75.68582153 ...,  65.58367157  63.89118958\n",
      "   63.89118958]\n",
      " [ 71.09062958  69.11636353  75.53417969 ...,  65.68663788  64.11136627\n",
      "   64.11136627]\n",
      " [ 70.96915436  69.02787781  75.49897003 ...,  65.70424652  64.55738068\n",
      "   64.55738068]\n",
      " ..., \n",
      " [ 70.59555054  68.69029236  75.71533966 ...,  65.75860596  65.3919754\n",
      "   65.3919754 ]\n",
      " [ 70.05827332  68.62102509  75.64608765 ...,  65.81121063  65.61867523\n",
      "   65.61867523]\n",
      " [ 70.8110733   68.05539703  75.61241913 ...,  64.79563904  63.98587036\n",
      "   63.98587036]]\n",
      "Alphas: [[ 0.        ]\n",
      " [ 0.14285715]\n",
      " [ 0.2857143 ]\n",
      " [ 0.42857143]\n",
      " [ 0.5714286 ]\n",
      " [ 0.71428573]\n",
      " [ 0.85714287]\n",
      " [ 1.        ]]\n",
      "Lambdas: [[ 700.24066162]\n",
      " [ 554.28198242]\n",
      " [ 554.28198242]\n",
      " [ 605.90710449]\n",
      " [ 657.53216553]\n",
      " [ 746.99053955]\n",
      " [ 842.45928955]\n",
      " [ 232.98251343]]\n",
      "Tols: [[ 0.001]\n",
      " [ 0.001]\n",
      " [ 0.001]\n",
      " [ 0.001]\n",
      " [ 0.001]\n",
      " [ 0.001]\n",
      " [ 0.001]\n",
      " [ 0.001]]\n",
      "RMSE: [[ 3.24046135  3.16654468  3.25880527]\n",
      " [ 3.20164943  2.99859762  3.18869185]\n",
      " [ 3.23561239  3.03012371  3.21810937]\n",
      " [ 3.29355311  3.07985282  3.27594423]\n",
      " [ 3.33344388  3.11671042  3.31554604]\n",
      " [ 3.40074492  3.18389821  3.38620782]\n",
      " [ 3.46312881  3.24788308  3.45339441]\n",
      " [ 3.1622045   2.96993709  3.12110662]]\n"
     ]
    }
   ],
   "source": [
    "pred_val, loss = run_glm(nFolds, nAlphas, nLambdas, xtrain, ytrain, xtest, ytest, wtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods to store Predictions in MapD DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(loss):\n",
    "    first = True\n",
    "    prev_val = None\n",
    "\n",
    "    for i in range(len(loss)):\n",
    "        curr_val = loss[i][2]\n",
    "        if first:\n",
    "            prev_val = curr_val\n",
    "            ind = i\n",
    "            first = False\n",
    "        elif curr_val - prev_val < 0:\n",
    "            prev_val = curr_val\n",
    "            ind = i\n",
    "    return ind\n",
    "\n",
    "def insert_results(pred_val, n_table, n_predcol, loss):\n",
    "    ind = get_index(loss)\n",
    "    \n",
    "    # predicted values from dataframe to list\n",
    "    df_pred = pd.DataFrame(pred_val[ind][np.newaxis][0].T)\n",
    "    df_src_test = df_src.to_pandas()\n",
    "    df_src_test.reset_index(inplace=True,drop=True)\n",
    "    df_src_test[n_predcol] = df_pred\n",
    "    \n",
    "    query_pred_drop = 'DROP TABLE IF EXISTS {};'.format(n_table)\n",
    "    query_pred_create = 'CREATE TABLE {}({} BIGINT NOT NULL, {} INT);'.format(n_table, key_col, n_predcol)\n",
    "    \n",
    "    # initialize a cursor to mapd\n",
    "    cur = con.cursor()\n",
    "\n",
    "    cur.execute(query_pred_drop)\n",
    "    cur.execute(query_pred_create)\n",
    "    \n",
    "    cur.close()\n",
    "    \n",
    "    con.load_table('prediction_table',df_src_test.itertuples(index=False))\n",
    "\n",
    "    print(\"Predicted values inserted in MapD\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert records in MapD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values inserted in MapD\n",
      "\n",
      "Join Query is: SELECT a.overall_rating,b.overall_rating_Pred FROM Player_Attributes a, prediction_table b WHERE a.rowid = b.map_id\n",
      "\n",
      "   overall_rating  overall_rating_Pred\n",
      "0              74                   73\n",
      "1              74                   74\n",
      "2              74                   74\n",
      "3              74                   73\n",
      "4              74                   73\n",
      "5              75                   74\n",
      "6              75                   74\n",
      "7              75                   74\n",
      "8              75                   74\n",
      "9              75                   74\n"
     ]
    }
   ],
   "source": [
    "if storage == 1:\n",
    "    \n",
    "    n_table = 'prediction_table'\n",
    "    n_predcol = response_col+'_Pred'\n",
    "    \n",
    "    insert_results(pred_val, n_table, n_predcol, loss)\n",
    "    \n",
    "    query_join = '''SELECT a.{},b.{} FROM Player_Attributes a, {} b WHERE a.rowid = b.{}'''.format(response_col,n_predcol,n_table,key_col)\n",
    "    print('Join Query is: {}\\n'.format(query_join))\n",
    "    \n",
    "    df_join = con.select_ipc(query_join)\n",
    "    pprint(df_join.head(10))\n",
    "    \n",
    "    con.close()\n",
    "else:\n",
    "    con.close()\n",
    "    print('Connection closed without inserting predictions in MapD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyg]",
   "language": "python",
   "name": "conda-env-pyg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
