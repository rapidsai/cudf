# SPDX-FileCopyrightText: Copyright (c) 2026, NVIDIA CORPORATION. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
import argparse
import hashlib
from typing import NamedTuple, Self

import yaml

BYTE_TYPE = "unsigned char"
SIZE_TYPE = "unsigned long"
STORAGE_SPEC = "static constexpr"
LIST_LINE_WIDTH = 32
NAMESPACE_PREFIX = "jit_"

### json schema

"""entries
[
    $id: {
        "type": "sources",
        "sources": [
            {
                "file": string,
                "dest": string
            }
        ],
        "include_directories": [string]
    },
    $id: {
        "type": "strings",
        "strings": list[string]
    }
]
"""


PREAMBLE = f"""
/// Auto-generated by jit_embed.py. Do not edit directly.
#pragma once

extern "C" {{

typedef struct {NAMESPACE_PREFIX}bytes_t {{
    {BYTE_TYPE} const * data;
    {SIZE_TYPE} size;
}} {NAMESPACE_PREFIX}bytes_t;

typedef struct {NAMESPACE_PREFIX}byte_range_t {{
    {SIZE_TYPE} offset;
    {SIZE_TYPE} size;
}} {NAMESPACE_PREFIX}byte_range_t;

typedef struct {NAMESPACE_PREFIX}bytes_array_t {{
    {NAMESPACE_PREFIX}bytes_t bytes;
    {NAMESPACE_PREFIX}byte_range_t const * ranges;
    {SIZE_TYPE} num_ranges;
}} {NAMESPACE_PREFIX}bytes_array_t;

}}

"""


def list_string(strings: list[str]) -> str:
    lines = []
    for i in range(0, len(strings), LIST_LINE_WIDTH):
        line = ", ".join(strings[i : i + LIST_LINE_WIDTH])
        lines.append(line)
    return ",\n".join(lines)


def byte_hex_string(value: int) -> str:
    return f"0x{value:02X}"


class CXXVarDecl(NamedTuple):
    id: str
    expr: str

    @staticmethod
    def of_bytes(id: str, data: bytes, alignment: int) -> Self:
        byte_array = list_string([byte_hex_string(b) for b in data])
        expr = f"""alignas({alignment}) {STORAGE_SPEC} {BYTE_TYPE} const {id}[{len(data)}] = {{
{byte_array}
}};"""
        return CXXVarDecl(id=id, expr=expr)

    @staticmethod
    def of_size(id: str, size: int) -> Self:
        expr = f"{STORAGE_SPEC} {SIZE_TYPE} const {id} = {size}ULL;"
        return CXXVarDecl(id=id, expr=expr)

    def decl(self: Self) -> str:
        return f"""{self.expr}"""


class CXXSizeArrayDecl(NamedTuple):
    id: str
    sizes: list[int]

    @staticmethod
    def of_sizes(id: str, sizes: list[int]) -> Self:
        return CXXSizeArrayDecl(id=id, sizes=sizes)

    def var(self: Self) -> CXXVarDecl:
        size_array = list_string([f"{size}ULL" for size in self.sizes])
        expr = f"""{STORAGE_SPEC} {SIZE_TYPE} const {self.id}[{len(self.sizes)}] = {{
{size_array}
}};"""
        return CXXVarDecl(id=self.id, expr=expr)


class CXXBytesDecl(NamedTuple):
    id: str
    data: bytes
    alignment: int
    num_null_terminators: int

    @staticmethod
    def of_bytes(
        id: str, data: bytes, alignment: int, num_null_terminators: int
    ) -> Self:
        return CXXBytesDecl(
            id=id,
            data=data,
            alignment=alignment,
            num_null_terminators=num_null_terminators,
        )

    def var(self: Self) -> CXXVarDecl:
        # exclude null terminator from length
        size_decl = CXXVarDecl.of_size(
            id=f"{self.id}_size", size=len(self.data)
        )

        data = self.data + b"\0" * self.num_null_terminators

        data_decl = CXXVarDecl.of_bytes(
            id=f"{self.id}_data", data=data, alignment=self.alignment
        )

        return CXXVarDecl(
            id=self.id,
            expr=f"""
{data_decl.decl()}

{size_decl.decl()}


{STORAGE_SPEC} {NAMESPACE_PREFIX}bytes_t const {self.id} = {{
    .data = {data_decl.id},
    .size = {size_decl.id}
}};
""",
        )


class CXXRangesDecl(NamedTuple):
    id: str
    ranges: list[tuple[int, int]]  # list of (offset, size)

    @staticmethod
    def of_ranges(id: str, ranges: list[tuple[int, int]]) -> Self:
        return CXXRangesDecl(id=id, ranges=ranges)

    def var(self: Self) -> CXXVarDecl:
        ranges_str = [
            f"{{{offset}UL, {size}UL}}" for offset, size in self.ranges
        ]

        ranges_str_formatted = list_string(ranges_str)

        expr = f"""{STORAGE_SPEC} {NAMESPACE_PREFIX}byte_range_t const {self.id}[{len(self.ranges)}] = {{
{ranges_str_formatted}
}};"""
        return CXXVarDecl(id=self.id, expr=expr)


class CXXArrayOfBytesDecl(NamedTuple):
    id: str
    data: bytes
    alignment: int
    ranges: list[tuple[int, int]]  # list of (offset, size)

    @staticmethod
    def of_byte_ranges(
        id: str,
        data: bytes,
        ranges: list[tuple[int, int]],
        alignment: int,
    ) -> Self:
        return CXXArrayOfBytesDecl(
            id=id,
            data=data,
            alignment=alignment,
            ranges=ranges,
        )

    def var(self: Self) -> CXXVarDecl:
        bytes_decl = CXXBytesDecl.of_bytes(
            id=f"{self.id}_bytes",
            data=self.data,
            alignment=self.alignment,
            num_null_terminators=0,
        )

        ranges_decl = CXXRangesDecl.of_ranges(
            id=f"{self.id}_ranges", ranges=self.ranges
        )

        expr = f"""
{bytes_decl.var().decl()}

{ranges_decl.var().decl()}

{STORAGE_SPEC} {NAMESPACE_PREFIX}bytes_array_t const {self.id} = {{
    .bytes = {bytes_decl.id},
    .ranges = {ranges_decl.id},
    .num_ranges = {len(self.ranges)}
}};
"""

        return CXXVarDecl(
            id=self.id,
            expr=expr,
        )


def merge_bytes_with_null_terminators(
    bytes_lists: list[bytes],
) -> tuple[bytes, list[tuple[int, int]]]:
    merged: bytes = bytes()
    ranges: list[tuple[int, int]] = []

    for byte_data in bytes_lists:
        ranges.append((len(merged), len(byte_data)))
        merged += byte_data + b"\0"

    return merged, ranges


def generate_cxx_strings_data(id: str, strings: list[str]) -> str:
    data, ranges = merge_bytes_with_null_terminators(
        [s.encode("utf-8") for s in strings]
    )

    sha = hashlib.sha256()
    sha.update(data)
    data_hash: bytes = sha.digest()

    arrays_decl = CXXArrayOfBytesDecl.of_byte_ranges(
        id=f"{id}",
        data=data,
        alignment=1,
        ranges=ranges,
    )

    data_hash_decl: CXXBytesDecl = CXXBytesDecl.of_bytes(
        id=f"{id}_hash",
        data=data_hash,
        alignment=1,
        num_null_terminators=0,
    )

    return f"""
{arrays_decl.var().decl()}

{data_hash_decl.var().decl()}
"""


def load_file_bytes(file_path: str) -> bytes:
    with open(file_path, "rb") as f:
        return f.read()


def generate_cxx_source_files_data(
    id: str,
    file_paths: list[str],
    dests: list[str],
    include_directories: list[str] = [],
) -> str:
    files_bytes, files_ranges = merge_bytes_with_null_terminators(
        [load_file_bytes(p) for p in file_paths]
    )

    merged_dests_bytes, merged_dests_ranges = (
        merge_bytes_with_null_terminators([d.encode("utf-8") for d in dests])
    )

    merged_include_directories_bytes, merged_include_directories_ranges = (
        merge_bytes_with_null_terminators(
            [d.encode("utf-8") for d in include_directories]
        )
    )

    # compute combined sha256 hash of all files
    sha = hashlib.sha256()
    sha.update(files_bytes)
    sha.update(merged_dests_bytes)
    sha.update(merged_include_directories_bytes)

    hash: bytes = sha.digest()

    file_destinations_decls: CXXArrayOfBytesDecl = (
        CXXArrayOfBytesDecl.of_byte_ranges(
            id=f"{id}_file_destinations",
            data=merged_dests_bytes,
            ranges=merged_dests_ranges,
            alignment=1,
        )
    )

    file_data_decl: CXXArrayOfBytesDecl = CXXArrayOfBytesDecl.of_byte_ranges(
        id=f"{id}_file_data",
        data=files_bytes,
        ranges=files_ranges,
        alignment=1,
    )

    include_directories_decls: CXXArrayOfBytesDecl = (
        CXXArrayOfBytesDecl.of_byte_ranges(
            id=f"{id}_include_directories",
            data=merged_include_directories_bytes,
            ranges=merged_include_directories_ranges,
            alignment=1,
        )
    )

    hash_decl: CXXBytesDecl = CXXBytesDecl.of_bytes(
        id=f"{id}_hash",
        data=hash,
        alignment=1,
        num_null_terminators=0,
    )

    # TODO: add lz4 compression and decompression as options (default)

    return f"""
{file_destinations_decls.var().decl()}

{file_data_decl.var().decl()}

{include_directories_decls.var().decl()}

{hash_decl.var().decl()}
"""


# TODO: write a schema validator for the input YAML


def generate_embed_source(entries: dict[str, dict[str, dict]]) -> str:
    code: str = ""

    for entry_id, entry_value in entries.items():
        entry_type = entry_value["type"]

        if entry_type == "sources":
            sources: list[dict] = entry_value["sources"]
            file_paths = [s["file"] for s in sources]
            dests = [s["dest"] for s in sources]
            include_directories: list[str] = entry_value["include_directories"]
            code += generate_cxx_source_files_data(
                entry_id, file_paths, dests, include_directories
            )

        elif entry_type == "strings":
            options: list[str] = entry_value["strings"]
            code += generate_cxx_strings_data(entry_id, options)

        else:
            raise ValueError(f"Unknown type: {entry_type}")

    return f"""
{PREAMBLE}

extern "C" {{

{code}

}}

"""


# Usage: embed.py --input <input file> --output <output file>
def main():
    parser = argparse.ArgumentParser(
        description="Embed headers, options, or binary blobs into C++ source code."
    )

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="YAML description of what to embed",
    )

    parser.add_argument(
        "--output", type=str, required=True, help="Output C++ source file"
    )

    args = parser.parse_args()

    with open(args.input, "rb") as f:
        description = yaml.safe_load(f)
    code = generate_embed_source(description)

    with open(args.output, "w") as f:
        f.write(code)


if __name__ == "__main__":
    main()
