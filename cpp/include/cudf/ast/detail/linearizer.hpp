/*
 * Copyright (c) 2020-2021, NVIDIA CORPORATION.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#pragma once

#include <cudf/ast/detail/operators.hpp>
#include <cudf/ast/expressions.hpp>
#include <cudf/scalar/scalar_device_view.cuh>
#include <cudf/table/table_view.hpp>
#include <cudf/types.hpp>

#include <numeric>

#include <thrust/optional.h>

namespace cudf {
namespace ast {

// Forward declaration
enum class table_reference;
class literal;
class column_reference;
class expression;

namespace detail {

/**
 * @brief Enum defining data reference types used by a node.
 *
 * This enum is device-specific. For instance, intermediate data references are generated by the
 * linearization process but cannot be explicitly created by the user.
 */
enum class device_data_reference_type {
  COLUMN,       // A value in a table column
  LITERAL,      // A literal value
  INTERMEDIATE  // An internal temporary value
};

/**
 * @brief A device data reference describes a source of data used by a node.
 *
 * This is a POD class used to create references describing data type and locations for consumption
 * by the `row_evaluator`.
 */
struct alignas(8) device_data_reference {
  device_data_reference(device_data_reference_type reference_type,
                        cudf::data_type data_type,
                        cudf::size_type data_index,
                        table_reference table_source);

  device_data_reference(device_data_reference_type reference_type,
                        cudf::data_type data_type,
                        cudf::size_type data_index);

  const device_data_reference_type reference_type;  // Source of data
  const cudf::data_type data_type;                  // Type of data
  const cudf::size_type data_index;                 // The column index of a table, index of a
                                                    // literal, or index of an intermediate
  const table_reference table_source;

  inline bool operator==(const device_data_reference& rhs) const
  {
    return std::tie(data_index, reference_type, table_source) ==
           std::tie(rhs.data_index, rhs.reference_type, rhs.table_source);
  }
};

/**
 * @brief The linearizer traverses an abstract syntax tree to prepare for execution on the device.
 *
 * This class is part of a "visitor" pattern with the `node` class.
 *
 * This class does pre-processing work on the host, validating operators and operand data types. It
 * traverses downward from a root node in a depth-first fashion, capturing information about
 * the nodes and constructing vectors of information that are later used by the device for
 * evaluating the abstract syntax tree as a "linear" list of operators whose input dependencies are
 * resolved into intermediate data storage in shared memory.
 */
class linearizer {
 public:
  /**
   * @brief Construct a new linearizer object
   *
   * @param expr The expression to create an evaluable linearizer for.
   * @param left The left table used for evaluating the abstract syntax tree.
   * @param right The right table used for evaluating the abstract syntax tree.
   */
  linearizer(node const& expr, cudf::table_view left, cudf::table_view right)
    : _left{left}, _right{right}, _node_count{0}, _intermediate_counter{}
  {
    expr.accept(*this);
  }

  /**
   * @brief Construct a new linearizer object
   *
   * @param expr The expression to create an evaluable linearizer for.
   * @param table The table used for evaluating the abstract syntax tree.
   */
  linearizer(node const& expr, cudf::table_view table)
    : _left{table}, _right{table}, _node_count{0}, _intermediate_counter{}
  {
    expr.accept(*this);
  }

  /**
   * @brief Get the root data type of the abstract syntax tree.
   *
   * @return cudf::data_type
   */
  cudf::data_type root_data_type() const;

  /**
   * @brief Get the maximum number of intermediates stored by the abstract syntax tree.
   *
   * @return cudf::size_type
   */
  cudf::size_type intermediate_count() const { return _intermediate_counter.get_max_used(); }

  /**
   * @brief Get the device data references.
   *
   * @return std::vector<detail::device_data_reference>
   */
  std::vector<detail::device_data_reference> const& data_references() const
  {
    return _data_references;
  }

  /**
   * @brief Get the operators.
   *
   * @return std::vector<ast_operator>
   */
  std::vector<ast_operator> const& operators() const { return _operators; }

  /**
   * @brief Get the operator source indices.
   *
   * @return std::vector<cudf::size_type>
   */
  std::vector<cudf::size_type> const& operator_source_indices() const
  {
    return _operator_source_indices;
  }

  /**
   * @brief Get the literal device views.
   *
   * @return std::vector<cudf::detail::fixed_width_scalar_device_view_base>
   */
  std::vector<cudf::detail::fixed_width_scalar_device_view_base> const& literals() const
  {
    return _literals;
  }

  /**
   * @brief Visit a literal node.
   *
   * @param expr Literal node.
   * @return cudf::size_type Index of device data reference for the node.
   */
  cudf::size_type visit(literal const& expr);

  /**
   * @brief Visit a column reference node.
   *
   * @param expr Column reference node.
   * @return cudf::size_type Index of device data reference for the node.
   */
  cudf::size_type visit(column_reference const& expr);

  /**
   * @brief Visit an expression node.
   *
   * @param expr Expression node.
   * @return cudf::size_type Index of device data reference for the node.
   */
  cudf::size_type visit(expression const& expr);

  /**
   * @brief Internal class used to track the utilization of intermediate storage locations.
   *
   * As nodes are being evaluated, they may generate "intermediate" data that is immediately
   * consumed. Rather than manifesting this data in global memory, we can store intermediates of any
   * fixed width type (up to 8 bytes) by placing them in shared memory. This class helps to track
   * the number and indices of intermediate data in shared memory using a give-take model. Locations
   * in shared memory can be "taken" and used for storage, "given back," and then later re-used.
   * This aims to minimize the maximum amount of shared memory needed at any point during the
   * evaluation.
   *
   */
  class intermediate_counter {
   public:
    intermediate_counter() : used_values(), max_used(0) {}
    cudf::size_type take();
    void give(cudf::size_type value);
    cudf::size_type get_max_used() const { return max_used; }

   private:
    cudf::size_type find_first_missing() const;
    std::vector<cudf::size_type> used_values;
    cudf::size_type max_used;
  };

 private:
  std::vector<cudf::size_type> visit_operands(
    std::vector<std::reference_wrapper<const node>> operands);
  cudf::size_type add_data_reference(detail::device_data_reference data_ref);

  // State information about the "linearized" GPU execution plan
  cudf::table_view const& _left;
  cudf::table_view const& _right;
  cudf::size_type _node_count;
  intermediate_counter _intermediate_counter;
  std::vector<detail::device_data_reference> _data_references;
  std::vector<ast_operator> _operators;
  std::vector<cudf::size_type> _operator_source_indices;
  std::vector<cudf::detail::fixed_width_scalar_device_view_base> _literals;
};

// Type trait for wrapping nullable types in a thrust::optional. Non-nullable
// types are returned as is.
template <typename T, bool has_nulls>
struct possibly_null_value;

template <typename T>
struct possibly_null_value<T, true> {
  using type = thrust::optional<T>;
};

template <typename T>
struct possibly_null_value<T, false> {
  using type = T;
};

template <typename T, bool has_nulls>
using possibly_null_value_t = typename possibly_null_value<T, has_nulls>::type;

// Type used for intermediate storage in expression evaluation.
template <bool has_nulls>
using IntermediateDataType = possibly_null_value_t<std::int64_t, has_nulls>;

/**
 * @brief A container of all device data required to evaluate an expression on tables.
 *
 * This struct should never be instantiated directly. It is created by the
 * `ast_plan` on construction, and the resulting member is publicly accessible
 * for passing to kernels for constructing an `expression_evaluator`.
 *
 */
struct device_ast_plan {
  device_span<const detail::device_data_reference> data_references;
  device_span<const cudf::detail::fixed_width_scalar_device_view_base> literals;
  device_span<const ast_operator> operators;
  device_span<const cudf::size_type> operator_source_indices;
  cudf::size_type num_intermediates;
  int shmem_per_thread;
};

/**
 * @brief Preprocessor for an expression acting on tables to generate data suitable for AST
 * expression evaluation on the GPU.
 *
 * On construction, an AST plan creates a single "packed" host buffer of all
 * data arrays that will be necessary to evaluate an expression on a pair of
 * tables. This data is copied to a single contiguous device buffer, and
 * pointers are generated to the individual components. Because the plan tends
 * to be small, this is the most efficient approach for low latency. All the
 * data required on the GPU can be accessed via the convenient `dev_plan`
 * member struct, which can be used to construct an `expression_evaluator` on
 * the device.
 *
 * Note that the resulting device data cannot be used once this class goes out of scope.
 */
struct ast_plan {
  /**
   * @brief Construct an AST plan for an expression operating on two tables.
   *
   * @param expr The expression for which to construct a plan.
   * @param left The left table on which the expression acts.
   * @param right The right table on which the expression acts.
   * @param has_nulls Boolean indicator of whether or not the data contains nulls.
   * @param stream Stream view on which to allocate resources and queue execution.
   * @param mr Device memory resource used to allocate the returned column's device.
   */
  ast_plan(node const& expr,
           cudf::table_view left,
           cudf::table_view right,
           bool has_nulls,
           rmm::cuda_stream_view stream,
           rmm::mr::device_memory_resource* mr)
    : _linearizer(expr, left, right)
  {
    std::vector<cudf::size_type> sizes;
    std::vector<const void*> data_pointers;

    extract_size_and_pointer(_linearizer.data_references(), sizes, data_pointers);
    extract_size_and_pointer(_linearizer.literals(), sizes, data_pointers);
    extract_size_and_pointer(_linearizer.operators(), sizes, data_pointers);
    extract_size_and_pointer(_linearizer.operator_source_indices(), sizes, data_pointers);

    // Create device buffer
    auto const buffer_size = std::accumulate(sizes.cbegin(), sizes.cend(), 0);
    auto buffer_offsets    = std::vector<int>(sizes.size());
    thrust::exclusive_scan(sizes.cbegin(), sizes.cend(), buffer_offsets.begin(), 0);

    auto h_data_buffer = std::make_unique<char[]>(buffer_size);
    for (unsigned int i = 0; i < data_pointers.size(); ++i) {
      std::memcpy(h_data_buffer.get() + buffer_offsets[i], data_pointers[i], sizes[i]);
    }

    _device_data_buffer = rmm::device_buffer(h_data_buffer.get(), buffer_size, stream, mr);

    stream.synchronize();

    // Create device pointers to components of plan
    auto device_data_buffer_ptr = static_cast<const char*>(_device_data_buffer.data());
    dev_plan.data_references    = device_span<const detail::device_data_reference>(
      reinterpret_cast<const detail::device_data_reference*>(device_data_buffer_ptr +
                                                             buffer_offsets[0]),
      _linearizer.data_references().size());
    dev_plan.literals = device_span<const cudf::detail::fixed_width_scalar_device_view_base>(
      reinterpret_cast<const cudf::detail::fixed_width_scalar_device_view_base*>(
        device_data_buffer_ptr + buffer_offsets[1]),
      _linearizer.literals().size());
    dev_plan.operators = device_span<const ast_operator>(
      reinterpret_cast<const ast_operator*>(device_data_buffer_ptr + buffer_offsets[2]),
      _linearizer.operators().size());
    dev_plan.operator_source_indices = device_span<const cudf::size_type>(
      reinterpret_cast<const cudf::size_type*>(device_data_buffer_ptr + buffer_offsets[3]),
      _linearizer.operator_source_indices().size());
    dev_plan.num_intermediates = _linearizer.intermediate_count();
    dev_plan.shmem_per_thread  = static_cast<int>(
      (has_nulls ? sizeof(IntermediateDataType<true>) : sizeof(IntermediateDataType<false>)) *
      dev_plan.num_intermediates);
  }

  /**
   * @brief Construct an AST plan for an expression operating on one table.
   *
   * @param expr The expression for which to construct a plan.
   * @param table The table on which the expression acts.
   * @param has_nulls Boolean indicator of whether or not the data contains nulls.
   * @param stream Stream view on which to allocate resources and queue execution.
   * @param mr Device memory resource used to allocate the returned column's device.
   */
  ast_plan(node const& expr,
           cudf::table_view table,
           bool has_nulls,
           rmm::cuda_stream_view stream,
           rmm::mr::device_memory_resource* mr)
    : ast_plan(expr, table, table, has_nulls, stream, mr)
  {
  }

  cudf::data_type output_type() const { return _linearizer.root_data_type(); }

  device_ast_plan
    dev_plan;  ///< The collection of data required to evaluate the expression on the device.

 private:
  /**
   * @brief Helper function for adding components (operators, literals, etc) to AST plan
   *
   * @tparam T  The underlying type of the input `std::vector`
   * @param[in]  v  The `std::vector` containing components (operators, literals, etc).
   * @param[in,out]  sizes  The `std::vector` containing the size of each data buffer.
   * @param[in,out]  data_pointers  The `std::vector` containing pointers to each data buffer.
   */
  template <typename T>
  void extract_size_and_pointer(std::vector<T> const& v,
                                std::vector<cudf::size_type>& sizes,
                                std::vector<const void*>& data_pointers)
  {
    auto const data_size = sizeof(T) * v.size();
    sizes.push_back(data_size);
    data_pointers.push_back(v.data());
  }

  rmm::device_buffer
    _device_data_buffer;  ///< The device-side data buffer containing the plan information, which is
                          ///< owned by this class and persists until it is destroyed.
  linearizer const _linearizer;  ///< The linearizer created from the provided expression that is
                                 ///< used to construct device-side operators and references.
};

}  // namespace detail

}  // namespace ast

}  // namespace cudf
